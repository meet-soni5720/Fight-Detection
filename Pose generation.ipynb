{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import zlib\n",
    "import yaml\n",
    "import json\n",
    "import struct\n",
    "import tempfile\n",
    "import posixpath\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import scipy.ndimage as ndi\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MAXIMUM_RADIUS = 1\n",
    "\n",
    "PART_NAMES = [\n",
    "     \"leftShoulder\",\"rightShoulder\", \"leftElbow\", \"rightElbow\", \"leftWrist\", \"rightWrist\",\n",
    "    \"leftHip\", \"rightHip\", \"leftKnee\", \"rightKnee\", \"leftAnkle\", \"rightAnkle\"\n",
    "]\n",
    "\n",
    "POSE_CHAIN = [\n",
    "    \n",
    "    (\"leftShoulder\", \"leftElbow\"), (\"leftElbow\", \"leftWrist\"),\n",
    "    (\"leftShoulder\", \"leftHip\"), (\"leftHip\", \"leftKnee\"),\n",
    "    (\"leftKnee\", \"leftAnkle\"),(\"rightShoulder\", \"rightElbow\"), (\"rightElbow\", \"rightWrist\"),\n",
    "    (\"rightShoulder\", \"rightHip\"), (\"rightHip\", \"rightKnee\"),\n",
    "    (\"rightKnee\", \"rightAnkle\")\n",
    "]\n",
    "\n",
    "PART_IDS = {pn: pid for pid, pn in enumerate(PART_NAMES)}\n",
    "\n",
    "PARENT_CHILD_TUPLES = [(PART_IDS[parent], PART_IDS[child]) for parent, child in POSE_CHAIN]\n",
    "\n",
    "NUM_KEYPOINTS = len(PART_NAMES)\n",
    "\n",
    "CONNECTED_PART_NAMES = [\n",
    "    (\"leftHip\", \"leftShoulder\"), (\"leftElbow\", \"leftShoulder\"),\n",
    "    (\"leftElbow\", \"leftWrist\"), (\"leftHip\", \"leftKnee\"),\n",
    "    (\"leftKnee\", \"leftAnkle\"), (\"rightHip\", \"rightShoulder\"),\n",
    "    (\"rightElbow\", \"rightShoulder\"), (\"rightElbow\", \"rightWrist\"),\n",
    "    (\"rightHip\", \"rightKnee\"), (\"rightKnee\", \"rightAnkle\"),\n",
    "    (\"leftShoulder\", \"rightShoulder\"), (\"leftHip\", \"rightHip\")\n",
    "]\n",
    "\n",
    "CONNECTED_PART_INDICES = [(PART_IDS[a], PART_IDS[b]) for a, b in CONNECTED_PART_NAMES]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_nms_radius(poses, squared_nms_radius, point, keypoint_id):\n",
    "    for _, _, pose_coord in poses:\n",
    "        if np.sum((pose_coord[keypoint_id] - point) ** 2) <= squared_nms_radius:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def within_nms_radius_fast(pose_coords, squared_nms_radius, point):\n",
    "    if not pose_coords.shape[0]:\n",
    "        return False\n",
    "    return np.any(np.sum((pose_coords - point) ** 2, axis=1) <= squared_nms_radius)\n",
    "\n",
    "\n",
    "def get_instance_score(existing_poses, squared_nms_radius,keypoint_scores, keypoint_coords):\n",
    "    not_overlapped_scores = 0.\n",
    "    for keypoint_id in range(len(keypoint_scores)):\n",
    "        if not within_nms_radius(existing_poses, squared_nms_radius,keypoint_coords[keypoint_id], keypoint_id):\n",
    "            not_overlapped_scores += keypoint_scores[keypoint_id]\n",
    "    return not_overlapped_scores / len(keypoint_scores)\n",
    "\n",
    "\n",
    "def get_instance_score_fast(exist_pose_coords,squared_nms_radius,keypoint_scores, keypoint_coords):\n",
    "\n",
    "    if exist_pose_coords.shape[0]:\n",
    "        s = np.sum((exist_pose_coords - keypoint_coords) ** 2, axis=2) > squared_nms_radius\n",
    "        not_overlapped_scores = np.sum(keypoint_scores[np.all(s, axis=0)])\n",
    "    else:\n",
    "        not_overlapped_scores = np.sum(keypoint_scores)\n",
    "    return not_overlapped_scores / len(keypoint_scores)\n",
    "\n",
    "\n",
    "def score_is_max_in_local_window(keypoint_id, score, hmy, hmx, local_max_radius, scores):\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "\n",
    "    y_start = max(hmy - local_max_radius, 0)\n",
    "    y_end = min(hmy + local_max_radius + 1, height)\n",
    "    x_start = max(hmx - local_max_radius, 0)\n",
    "    x_end = min(hmx + local_max_radius + 1, width)\n",
    "\n",
    "    for y in range(y_start, y_end):\n",
    "        for x in range(x_start, x_end):\n",
    "            if scores[y, x, keypoint_id] > score:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def build_part_with_score(score_threshold, local_max_radius, scores):\n",
    "    parts = []\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "    num_keypoints = scores.shape[2]\n",
    "\n",
    "    for hmy in range(height):\n",
    "        for hmx in range(width):\n",
    "            for keypoint_id in range(num_keypoints):\n",
    "                score = scores[hmy, hmx, keypoint_id]\n",
    "                if score < score_threshold:\n",
    "                    continue\n",
    "                if score_is_max_in_local_window(keypoint_id, score, hmy, hmx,local_max_radius, scores):\n",
    "                    parts.append((score, keypoint_id, np.array((hmy, hmx))))\n",
    "    return parts\n",
    "\n",
    "\n",
    "def build_part_with_score_fast(score_threshold, local_max_radius, scores):\n",
    "    parts = []\n",
    "    num_keypoints = scores.shape[2]\n",
    "    lmd = 2 * local_max_radius + 1\n",
    "\n",
    "    # NOTE it seems faster to iterate over the keypoints and perform maximum_filter\n",
    "    # on each subarray vs doing the op on the full score array with size=(lmd, lmd, 1)\n",
    "    for keypoint_id in range(num_keypoints):\n",
    "        kp_scores = scores[:, :, keypoint_id].copy()\n",
    "        kp_scores[kp_scores < score_threshold] = 0.\n",
    "        max_vals = ndi.maximum_filter(kp_scores, size=lmd, mode='constant')\n",
    "        max_loc = np.logical_and(kp_scores == max_vals, kp_scores > 0)\n",
    "        max_loc_idx = max_loc.nonzero()\n",
    "        for y, x in zip(*max_loc_idx):\n",
    "            parts.append((scores[y, x, keypoint_id],keypoint_id,np.array((y, x))))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def traverse_to_targ_keypoint(edge_id, source_keypoint, target_keypoint_id, scores, offsets, output_stride, displacements):\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "\n",
    "    source_keypoint_indices = np.clip(np.round(source_keypoint / output_stride), a_min=0, a_max=[height - 1, width - 1]).astype(np.int32)\n",
    "\n",
    "    displaced_point = source_keypoint + displacements[source_keypoint_indices[0], source_keypoint_indices[1], edge_id]\n",
    "\n",
    "    displaced_point_indices = np.clip(np.round(displaced_point / output_stride), a_min=0, a_max=[height - 1, width - 1]).astype(np.int32)\n",
    "\n",
    "    score = scores[displaced_point_indices[0], displaced_point_indices[1], target_keypoint_id]\n",
    "\n",
    "    image_coord = displaced_point_indices * output_stride + offsets[\n",
    "        displaced_point_indices[0], displaced_point_indices[1], target_keypoint_id]\n",
    "\n",
    "    return score, image_coord\n",
    "\n",
    "\n",
    "def decode_pose(root_score, root_id, root_image_coord,scores,offsets,output_stride,displacements_fwd,displacements_bwd):\n",
    "    num_parts = scores.shape[2]\n",
    "    num_edges = len(PARENT_CHILD_TUPLES)\n",
    "\n",
    "    instance_keypoint_scores = np.zeros(num_parts)\n",
    "    instance_keypoint_coords = np.zeros((num_parts, 2))\n",
    "    instance_keypoint_scores[root_id] = root_score\n",
    "    instance_keypoint_coords[root_id] = root_image_coord\n",
    "\n",
    "    for edge in reversed(range(num_edges)):\n",
    "        target_keypoint_id, source_keypoint_id = PARENT_CHILD_TUPLES[edge]\n",
    "        if (instance_keypoint_scores[source_keypoint_id] > 0.0 and\n",
    "                instance_keypoint_scores[target_keypoint_id] == 0.0):\n",
    "            score, coords = traverse_to_targ_keypoint(edge,instance_keypoint_coords[source_keypoint_id],target_keypoint_id,scores, offsets, output_stride, displacements_bwd)\n",
    "            instance_keypoint_scores[target_keypoint_id] = score\n",
    "            instance_keypoint_coords[target_keypoint_id] = coords\n",
    "\n",
    "    for edge in range(num_edges):\n",
    "        source_keypoint_id, target_keypoint_id = PARENT_CHILD_TUPLES[edge]\n",
    "        if (instance_keypoint_scores[source_keypoint_id] > 0.0 and\n",
    "                instance_keypoint_scores[target_keypoint_id] == 0.0):\n",
    "            score, coords = traverse_to_targ_keypoint(edge,instance_keypoint_coords[source_keypoint_id],target_keypoint_id,scores, offsets, output_stride, displacements_fwd)\n",
    "            instance_keypoint_scores[target_keypoint_id] = score\n",
    "            instance_keypoint_coords[target_keypoint_id] = coords\n",
    "\n",
    "    return instance_keypoint_scores, instance_keypoint_coords\n",
    "\n",
    "\n",
    "\n",
    "def decode_multiple_poses(scores, offsets, displacements_fwd, displacements_bwd, output_stride,max_pose_detections=10, score_threshold=0.5, nms_radius=20, min_pose_score=0.5):\n",
    "\n",
    "    pose_count = 0\n",
    "    pose_scores = np.zeros(max_pose_detections)\n",
    "    pose_keypoint_scores = np.zeros((max_pose_detections, NUM_KEYPOINTS))\n",
    "    pose_keypoint_coords = np.zeros((max_pose_detections, NUM_KEYPOINTS, 2))\n",
    "\n",
    "    squared_nms_radius = nms_radius ** 2\n",
    "\n",
    "    scored_parts = build_part_with_score_fast(score_threshold, LOCAL_MAXIMUM_RADIUS, scores)\n",
    "    scored_parts = sorted(scored_parts, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # change dimensions from (h, w, x) to (h, w, x//2, 2) to allow return of complete coord array\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "    offsets = offsets.reshape(height, width, 2, -1).swapaxes(2, 3)\n",
    "    displacements_fwd = displacements_fwd.reshape(height, width, 2, -1).swapaxes(2, 3)\n",
    "    displacements_bwd = displacements_bwd.reshape(height, width, 2, -1).swapaxes(2, 3)\n",
    "\n",
    "    for root_score, root_id, root_coord in scored_parts:\n",
    "        root_image_coords = root_coord * output_stride + offsets[root_coord[0], root_coord[1], root_id]\n",
    "\n",
    "        if within_nms_radius_fast(pose_keypoint_coords[:pose_count, root_id, :], squared_nms_radius, root_image_coords):\n",
    "            continue\n",
    "\n",
    "        keypoint_scores, keypoint_coords = decode_pose(root_score, root_id, root_image_coords,scores, offsets, output_stride,displacements_fwd, displacements_bwd)\n",
    "\n",
    "        pose_score = get_instance_score_fast(pose_keypoint_coords[:pose_count, :, :], squared_nms_radius, keypoint_scores, keypoint_coords)\n",
    "\n",
    "        if min_pose_score == 0. or pose_score >= min_pose_score:\n",
    "            pose_scores[pose_count] = pose_score\n",
    "            pose_keypoint_scores[pose_count, :] = keypoint_scores\n",
    "            pose_keypoint_coords[pose_count, :, :] = keypoint_coords\n",
    "            pose_count += 1\n",
    "\n",
    "        if pose_count >= max_pose_detections:\n",
    "            break\n",
    "\n",
    "    return pose_scores, pose_keypoint_scores, pose_keypoint_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.join(tempfile.gettempdir(), '_posenet_weights')\n",
    "\n",
    "MODEL_DIR = './_models'\n",
    "DEBUG_OUTPUT = False\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "def converter_load_config(config_name='config.yaml'):\n",
    "    cfg_f = open(os.path.join(BASE_DIR, config_name), \"r+\")\n",
    "    cfg = yaml.load(cfg_f)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def to_output_strided_layers(convolution_def, output_stride):\n",
    "    current_stride = 1\n",
    "    rate = 1\n",
    "    block_id = 0\n",
    "    buff = []\n",
    "    for _a in convolution_def:\n",
    "        conv_type = _a[0]\n",
    "        stride = _a[1]\n",
    "        \n",
    "        if current_stride == output_stride:\n",
    "            layer_stride = 1\n",
    "            layer_rate = rate\n",
    "            rate *= stride\n",
    "        else:\n",
    "            layer_stride = stride\n",
    "            layer_rate = 1\n",
    "            current_stride *= stride\n",
    "        \n",
    "        buff.append({\n",
    "            'blockId': block_id,\n",
    "            'convType': conv_type,\n",
    "            'stride': layer_stride,\n",
    "            'rate': layer_rate,\n",
    "            'outputStride': current_stride\n",
    "        })\n",
    "        block_id += 1\n",
    "\n",
    "    return buff\n",
    "\n",
    "\n",
    "def load_variables(chkpoint, base_dir=BASE_DIR):\n",
    "    manifest_path = os.path.join(base_dir, chkpoint, \"manifest.json\")\n",
    "    if not os.path.exists(manifest_path):\n",
    "        print('Weights for checkpoint %s are not downloaded. Downloading to %s ...' % (chkpoint, base_dir))\n",
    "        download(chkpoint, base_dir)\n",
    "        assert os.path.exists(manifest_path)\n",
    "\n",
    "    with open(manifest_path) as f:\n",
    "        variables = json.load(f)\n",
    "\n",
    "    # with tf.variable_scope(None, 'MobilenetV1'):\n",
    "    for x in variables:\n",
    "        filename = variables[x][\"filename\"]\n",
    "        byte = open(os.path.join(base_dir, chkpoint, filename), 'rb').read()\n",
    "        fmt = str(int(len(byte) / struct.calcsize('f'))) + 'f'\n",
    "        d = struct.unpack(fmt, byte)\n",
    "        d = tf.cast(d, tf.float32)\n",
    "        d = tf.reshape(d, variables[x][\"shape\"])\n",
    "        variables[x][\"x\"] = tf.Variable(d, name=x)\n",
    "\n",
    "    return variables\n",
    "\n",
    "\n",
    "def _read_imgfile(path, width, height):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(float)\n",
    "    img = img * (2.0 / 255.0) - 1.0\n",
    "    return img\n",
    "\n",
    "\n",
    "def build_network(image, layers, variables):\n",
    "\n",
    "    def _weights(layer_name):\n",
    "        return variables[\"MobilenetV1/\" + layer_name + \"/weights\"]['x']\n",
    "\n",
    "    def _biases(layer_name):\n",
    "        return variables[\"MobilenetV1/\" + layer_name + \"/biases\"]['x']\n",
    "\n",
    "    def _depthwise_weights(layer_name):\n",
    "        return variables[\"MobilenetV1/\" + layer_name + \"/depthwise_weights\"]['x']\n",
    "\n",
    "    def _conv_to_output(mobile_net_output, output_layer_name):\n",
    "        w = tf.nn.conv2d(mobile_net_output, _weights(output_layer_name), [1, 1, 1, 1], padding='SAME')\n",
    "        w = tf.nn.bias_add(w, _biases(output_layer_name), name=output_layer_name)\n",
    "        return w\n",
    "\n",
    "    def _conv(inputs, stride, block_id):\n",
    "        return tf.nn.relu6(\n",
    "            tf.nn.conv2d(inputs, _weights(\"Conv2d_\" + str(block_id)), stride, padding='SAME')\n",
    "            + _biases(\"Conv2d_\" + str(block_id)))\n",
    "\n",
    "    def _separable_conv(inputs, stride, block_id, dilations):\n",
    "        if dilations is None:\n",
    "            dilations = [1, 1]\n",
    "\n",
    "        dw_layer = \"Conv2d_\" + str(block_id) + \"_depthwise\"\n",
    "        pw_layer = \"Conv2d_\" + str(block_id) + \"_pointwise\"\n",
    "\n",
    "        w = tf.nn.depthwise_conv2d(\n",
    "            inputs, _depthwise_weights(dw_layer), stride, 'SAME', rate=dilations, data_format='NHWC')\n",
    "        w = tf.nn.bias_add(w, _biases(dw_layer))\n",
    "        w = tf.nn.relu6(w)\n",
    "\n",
    "        w = tf.nn.conv2d(w, _weights(pw_layer), [1, 1, 1, 1], padding='SAME')\n",
    "        w = tf.nn.bias_add(w, _biases(pw_layer))\n",
    "        w = tf.nn.relu6(w)\n",
    "\n",
    "        return w\n",
    "\n",
    "    x = image\n",
    "    buff = []\n",
    "    with tf.variable_scope(None, 'MobilenetV1'):\n",
    "\n",
    "        for m in layers:\n",
    "            stride = [1, m['stride'], m['stride'], 1]\n",
    "            rate = [m['rate'], m['rate']]\n",
    "            if m['convType'] == \"conv2d\":\n",
    "                x = _conv(x, stride, m['blockId'])\n",
    "                buff.append(x)\n",
    "            elif m['convType'] == \"separableConv\":\n",
    "                x = _separable_conv(x, stride, m['blockId'], rate)\n",
    "                buff.append(x)\n",
    "\n",
    "    heatmaps = _conv_to_output(x, 'heatmap_2')\n",
    "    offsets = _conv_to_output(x, 'offset_2')\n",
    "    displacement_fwd = _conv_to_output(x, 'displacement_fwd_2')\n",
    "    displacement_bwd = _conv_to_output(x, 'displacement_bwd_2')\n",
    "    heatmaps = tf.sigmoid(heatmaps, 'heatmap')\n",
    "\n",
    "    return heatmaps, offsets, displacement_fwd, displacement_bwd\n",
    "\n",
    "\n",
    "def convert(model_id, model_dir, check=False):\n",
    "    cfg = converter_load_config()\n",
    "    checkpoints = cfg['checkpoints']\n",
    "    image_size = cfg['imageSize']\n",
    "    output_stride = cfg['outputStride']\n",
    "    chkpoint = checkpoints[model_id]\n",
    "\n",
    "    if chkpoint == 'mobilenet_v1_050':\n",
    "        mobile_net_arch = cfg['mobileNet50Architecture']\n",
    "    elif chkpoint == 'mobilenet_v1_075':\n",
    "        mobile_net_arch = cfg['mobileNet75Architecture']\n",
    "    else:\n",
    "        mobile_net_arch = cfg['mobileNet100Architecture']\n",
    "\n",
    "    width = image_size\n",
    "    height = image_size\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    cg = tf.Graph()\n",
    "    with cg.as_default():\n",
    "        layers = to_output_strided_layers(mobile_net_arch, output_stride)\n",
    "        variables = load_variables(chkpoint)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            image_ph = tf.placeholder(tf.float32, shape=[1, None, None, 3], name='image')\n",
    "            outputs = build_network(image_ph, layers, variables)\n",
    "\n",
    "            sess.run(\n",
    "                [outputs],\n",
    "                feed_dict={\n",
    "                    image_ph: [np.ndarray(shape=(height, width, 3), dtype=np.float32)]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            save_path = os.path.join(model_dir, 'checkpoints', 'model-%s.ckpt' % chkpoint)\n",
    "            if not os.path.exists(os.path.dirname(save_path)):\n",
    "                os.makedirs(os.path.dirname(save_path))\n",
    "            checkpoint_path = saver.save(sess, save_path, write_state=False)\n",
    "\n",
    "            tf.train.write_graph(cg, model_dir, \"model-%s.pbtxt\" % chkpoint)\n",
    "\n",
    "            # Freeze graph and write our final model file\n",
    "            freeze_graph(\n",
    "                input_graph=os.path.join(model_dir, \"model-%s.pbtxt\" % chkpoint),\n",
    "                input_saver=\"\",\n",
    "                input_binary=False,\n",
    "                input_checkpoint=checkpoint_path,\n",
    "                output_node_names='heatmap,offset_2,displacement_fwd_2,displacement_bwd_2',\n",
    "                restore_op_name=\"save/restore_all\",\n",
    "                filename_tensor_name=\"save/Const:0\",\n",
    "                output_graph=os.path.join(model_dir, \"model-%s.pb\" % chkpoint),\n",
    "                clear_devices=True,\n",
    "                initializer_nodes=\"\")\n",
    "\n",
    "            if check and os.path.exists(\"./images/tennis_in_crowd.jpg\"):\n",
    "                # Result\n",
    "                input_image = _read_imgfile(\"./images/tennis_in_crowd.jpg\", width, height)\n",
    "                input_image = np.array(input_image, dtype=np.float32)\n",
    "                input_image = input_image.reshape(1, height, width, 3)\n",
    "\n",
    "                heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "                    outputs,\n",
    "                    feed_dict={image_ph: input_image}\n",
    "                )\n",
    "\n",
    "                print(\"Test image stats\")\n",
    "                print(input_image)\n",
    "                print(input_image.shape)\n",
    "                print(np.mean(input_image))\n",
    "\n",
    "                heatmaps_result = heatmaps_result[0]\n",
    "\n",
    "                print(\"Heatmaps\")\n",
    "                print(heatmaps_result[0:1, 0:1, :])\n",
    "                print(heatmaps_result.shape)\n",
    "                print(np.mean(heatmaps_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_resolution(width, height, output_stride=16):\n",
    "    target_width = (int(width) // output_stride) * output_stride + 1\n",
    "    target_height = (int(height) // output_stride) * output_stride + 1\n",
    "    return target_width, target_height\n",
    "\n",
    "\n",
    "def _process_input(source_img, scale_factor=1.0, output_stride=16):\n",
    "    target_width, target_height = valid_resolution(\n",
    "        source_img.shape[1] * scale_factor, source_img.shape[0] * scale_factor, output_stride=output_stride)\n",
    "    scale = np.array([source_img.shape[0] / target_height, source_img.shape[1] / target_width])\n",
    "\n",
    "    input_img = cv2.resize(source_img, (target_width, target_height), interpolation=cv2.INTER_LINEAR)\n",
    "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    input_img = input_img * (2.0 / 255.0) - 1.0\n",
    "    input_img = input_img.reshape(1, target_height, target_width, 3)\n",
    "    return input_img, source_img, scale\n",
    "\n",
    "\n",
    "def read_cap(cap, scale_factor=1.0, output_stride=16):\n",
    "    res, img = cap.read()\n",
    "    if not res:\n",
    "        raise IOError(\"webcam failure\")\n",
    "    return _process_input(img, scale_factor, output_stride)\n",
    "\n",
    "\n",
    "def read_imgfile(path, scale_factor=1.0, output_stride=16):\n",
    "    img = cv2.imread(path)\n",
    "    return _process_input(img, scale_factor, output_stride)\n",
    "\n",
    "\n",
    "def draw_keypoints(\n",
    "        img, instance_scores, keypoint_scores, keypoint_coords,\n",
    "        min_pose_confidence=0.5, min_part_confidence=0.5):\n",
    "    cv_keypoints = []\n",
    "    for ii, score in enumerate(instance_scores):\n",
    "        if score < min_pose_confidence:\n",
    "            continue\n",
    "        for ks, kc in zip(keypoint_scores[ii, :], keypoint_coords[ii, :, :]):\n",
    "            if ks < min_part_confidence:\n",
    "                continue\n",
    "            cv_keypoints.append(cv2.KeyPoint(kc[1], kc[0], 10. * ks))\n",
    "    out_img = cv2.drawKeypoints(img, cv_keypoints, outImage=np.array([]))\n",
    "    return out_img\n",
    "\n",
    "\n",
    "def get_adjacent_keypoints(keypoint_scores, keypoint_coords, min_confidence=0.1):\n",
    "    results = []\n",
    "    for left, right in CONNECTED_PART_INDICES:\n",
    "        if keypoint_scores[left] < min_confidence or keypoint_scores[right] < min_confidence:\n",
    "            continue\n",
    "        results.append(\n",
    "            np.array([keypoint_coords[left][::-1], keypoint_coords[right][::-1]]).astype(np.int32),\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "def draw_skeleton(\n",
    "        img, instance_scores, keypoint_scores, keypoint_coords,\n",
    "        min_pose_confidence=0.5, min_part_confidence=0.5):\n",
    "    out_img = img\n",
    "    adjacent_keypoints = []\n",
    "    for ii, score in enumerate(instance_scores):\n",
    "        if score < min_pose_confidence:\n",
    "            continue\n",
    "        new_keypoints = get_adjacent_keypoints(\n",
    "            keypoint_scores[ii, :], keypoint_coords[ii, :, :], min_part_confidence)\n",
    "        adjacent_keypoints.extend(new_keypoints)\n",
    "    out_img = cv2.polylines(out_img, adjacent_keypoints, isClosed=False, color=(255, 255, 0))\n",
    "    return out_img\n",
    "\n",
    "\n",
    "def draw_skel_and_kp(img, instance_scores, keypoint_scores, keypoint_coords,min_pose_score=0.5, min_part_score=0.5):\n",
    "    out_img = np.ones(img.shape, dtype=np.uint8)\n",
    "    adjacent_keypoints = []\n",
    "    cv_keypoints = []\n",
    "    for ii, score in enumerate(instance_scores):\n",
    "        if score < min_pose_score:\n",
    "            continue\n",
    "\n",
    "        new_keypoints = get_adjacent_keypoints(keypoint_scores[ii, :], keypoint_coords[ii, :, :], min_part_score)\n",
    "        adjacent_keypoints.extend(new_keypoints)\n",
    "\n",
    "        for ks, kc in zip(keypoint_scores[ii, :], keypoint_coords[ii, :, :]):\n",
    "            if ks < min_part_score:\n",
    "                continue\n",
    "            cv_keypoints.append(cv2.KeyPoint(kc[1], kc[0], 10. * ks))\n",
    "\n",
    "    out_img = cv2.drawKeypoints(out_img, cv_keypoints, outImage=np.array([]), color=(255, 255, 0),flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    out_img = cv2.polylines(out_img, adjacent_keypoints, isClosed=False, color=(255, 255, 0))\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_id_to_ord(model_id):\n",
    "    if 0 <= model_id < 4:\n",
    "        return model_id  # id is already ordinal\n",
    "    elif model_id == 50:\n",
    "        return 0\n",
    "    elif model_id == 75:\n",
    "        return 1\n",
    "    elif model_id == 100:\n",
    "        return 2\n",
    "    else:  # 101\n",
    "        return 3\n",
    "\n",
    "\n",
    "def load_config(model_ord):\n",
    "    converter_cfg = converter_load_config()\n",
    "    checkpoints = converter_cfg['checkpoints']\n",
    "    output_stride = converter_cfg['outputStride']\n",
    "    checkpoint_name = checkpoints[model_ord]\n",
    "\n",
    "    model_cfg = {\n",
    "        'output_stride': output_stride,\n",
    "        'checkpoint_name': checkpoint_name,\n",
    "    }\n",
    "    return model_cfg\n",
    "\n",
    "\n",
    "def load_model(model_id, sess, model_dir=MODEL_DIR):\n",
    "    model_ord = model_id_to_ord(model_id)\n",
    "    model_cfg = load_config(model_ord)\n",
    "    model_path = os.path.join(model_dir, 'model-%s.pb' % model_cfg['checkpoint_name'])\n",
    "    if not os.path.exists(model_path):\n",
    "        print('Cannot find model file %s, converting from tfjs...' % model_path)\n",
    "        convert(model_ord, model_dir, check=False)\n",
    "        assert os.path.exists(model_path)\n",
    "\n",
    "    with tf.gfile.GFile(model_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    if DEBUG_OUTPUT:\n",
    "        graph_nodes = [n for n in graph_def.node]\n",
    "        names = []\n",
    "        for t in graph_nodes:\n",
    "            names.append(t.name)\n",
    "            print('Loaded graph node:', t.name)\n",
    "\n",
    "    offsets = sess.graph.get_tensor_by_name('offset_2:0')\n",
    "    displacement_fwd = sess.graph.get_tensor_by_name('displacement_fwd_2:0')\n",
    "    displacement_bwd = sess.graph.get_tensor_by_name('displacement_bwd_2:0')\n",
    "    heatmaps = sess.graph.get_tensor_by_name('heatmap:0')\n",
    "\n",
    "    return model_cfg, [heatmaps, offsets, displacement_fwd, displacement_bwd]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "CFG = converter_load_config()\n",
    "GOOGLE_CLOUD_STORAGE_DIR = CFG['GOOGLE_CLOUD_STORAGE_DIR']\n",
    "CHECKPOINTS = CFG['checkpoints']\n",
    "CHK = CFG['chk']\n",
    "\n",
    "\n",
    "def download_file(checkpoint, filename, base_dir):\n",
    "    output_path = os.path.join(base_dir, checkpoint, filename)\n",
    "    url = posixpath.join(GOOGLE_CLOUD_STORAGE_DIR, checkpoint, filename)\n",
    "    req = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(req)\n",
    "    if response.info().get('Content-Encoding') == 'gzip':\n",
    "        data = zlib.decompress(response.read(), zlib.MAX_WBITS | 32)\n",
    "    else:\n",
    "        # this path not tested since gzip encoding default on google server\n",
    "        # may need additional encoding/text handling if hit in the future\n",
    "        data = response.read()\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(data)\n",
    "\n",
    "\n",
    "def download(checkpoint, base_dir='./weights/'):\n",
    "    save_dir = os.path.join(base_dir, checkpoint)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    download_file(checkpoint, 'manifest.json', base_dir)\n",
    "    with open(os.path.join(save_dir, 'manifest.json'), 'r') as f:\n",
    "        json_dict = json.load(f)\n",
    "\n",
    "    for x in json_dict:\n",
    "        filename = json_dict[x]['filename']\n",
    "        print('Downloading', filename)\n",
    "        download_file(checkpoint, filename, base_dir)\n",
    "\n",
    "\n",
    "def main():\n",
    "    checkpoint = CHECKPOINTS[CHK]\n",
    "    download(checkpoint)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 101 \n",
    "scale_factor = 1.0\n",
    "notxt = False\n",
    "image_dir = \"../images/Violence reddit\"\n",
    "output_dir = \"../images/poses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d31c92743de5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-d31c92743de5>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mmodel_cfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0moutput_stride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_cfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'output_stride'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        model_cfg, model_outputs = load_model(model, sess)\n",
    "        output_stride = model_cfg['output_stride']\n",
    "\n",
    "        if output_dir:\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "        filenames = [f.path for f in os.scandir(image_dir) if f.is_file() and f.path.endswith(('.png', '.jpg'))]\n",
    "\n",
    "        start = time.time()\n",
    "        for f in filenames:\n",
    "            input_image, draw_image, output_scale = read_imgfile(f, scale_factor=scale_factor, output_stride=output_stride)\n",
    "\n",
    "            heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(model_outputs,feed_dict={'image:0': input_image})\n",
    "\n",
    "            pose_scores, keypoint_scores, keypoint_coords = decode_multiple_poses(\n",
    "                heatmaps_result.squeeze(axis=0),\n",
    "                offsets_result.squeeze(axis=0),\n",
    "                displacement_fwd_result.squeeze(axis=0),\n",
    "                displacement_bwd_result.squeeze(axis=0),\n",
    "                output_stride=output_stride,\n",
    "                max_pose_detections=10,\n",
    "                min_pose_score=0.25)\n",
    "\n",
    "            keypoint_coords *= output_scale\n",
    "\n",
    "            if output_dir:\n",
    "                draw_image = draw_skel_and_kp(draw_image, pose_scores, keypoint_scores, keypoint_coords,min_pose_score=0.25, min_part_score=0.25)\n",
    "\n",
    "                cv2.imwrite(os.path.join(output_dir, os.path.relpath(f, image_dir)), draw_image)\n",
    "\n",
    "            if not notxt:\n",
    "                print()\n",
    "                print(\"Results for image: %s\" % f)\n",
    "                for pi in range(len(pose_scores)):\n",
    "                    if pose_scores[pi] == 0.:\n",
    "                        break\n",
    "                    print('Pose #%d, score = %f' % (pi, pose_scores[pi]))\n",
    "                    for ki, (s, c) in enumerate(zip(keypoint_scores[pi, :], keypoint_coords[pi, :, :])):\n",
    "                        print('Keypoint %s, score = %f, coord = %s' % (PART_NAMES[ki], s, c))\n",
    "\n",
    "        print('Average FPS:', len(filenames) / (time.time() - start))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
